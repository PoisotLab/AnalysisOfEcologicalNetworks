\chapter[Significance testing]{The deeply flawed art of null hypothesis significance testing\label{chap:nhst}}

<<>>=
using EcologicalNetworks
import Mangal
using Statistics
@

Ecologists, like sadly a great majority of scientists, decide on the worthiness
of an observation by ignoring their best judgement, decades of training in
biology, and expertise; instead, we rely on whether some arbitrary value (the
\emph{p}-value) is lower than some even more arbitrary threshold (0.05). It all
seems very \emph{ad hoc} (it is). And yet, a surprising amount of literature on
ecological networks attempts to decide whether some observed value of a network
measure is "significant", and so it is with great reluctance that we will
dedicate a chapter to this practice.

\section{Fundamentals of network NHST}

Null Hypothesis Significance Testing (NHST) for ecological networks strives to
answer the following question: "if I observed the value $f_0$ for the measure
$f$ on a network $\mathbf{N}$, is it in the range of values expected by
chance?". Most often, we want to refine this question by asking if the value is
larger or smaller than we expect, and this is why this process usually involves
a one-tailed one-sample \emph{t}-test.

\subsection{Generating a sample}

Given a function $f$ and a network $\mathbf{N}$, NHST requires to measure the
distribution of possible values of  $f(\mathbf{N})$. For most measures (all of
them, in fact), there is no direct expression of this distribution, and so we
need to rely on an imperfect proxy: generating random networks. The exact models
under which these models are generated is explained in section \textbf{TK}.

\subsection{From the sample to the distribution}

\subsection{Estimating significance}

\section{Overview of the null models}

\subsection{Probabilistic models}

\subsection{Generalization of the probabilistic models}

\begin{equation}\label{eq:linearfilter}
  P_{ij} = \alpha_1 N_{ij} + \alpha_2 \frac{N_{\cdot j}}{S_1} + \alpha_3 \frac{N_{i\cdot}}{S_2} + \alpha_4 \frac{L}{S_1S_2}
\end{equation}

\begin{equation}\label{eq:lfnm1}
P = lf(N, \mathbf{\alpha} = (0, 0, 0, 1))
\end{equation}

\subsection{Permutational models}

\section{Application -- nestedness of oil-flowers pollination networks}

In this section, we will use the NHST process outline in figure~\ref{fig:nhst}
to determine whether bipartite networks are \emph{more} nested than expected by
chance, under two assumptions as to what drives the structure of the model

\ref{eq:lfnm1}

\subsection{Preparing the data and measuring nestedness}

We will first work on a dataset of pollination interactions between insects and
oil-flowers, collected by \textcite{BezMacMel09}.

<<>>=
oilflower_network = Mangal.network(929)
N = convert(UnipartiteNetwork, oilflower_network)
B = convert(BipartiteNetwork, N)
@

We will use NODF (\textbf{tk}) to measure the nestedness of this network. This
is an important step, as it will provide our $f_0$, the reference value,
measured on the empirical network:

<<>>=
f0 = nodf(B)
@

Recall that NODF takes values between 0 and 1, where 1 indicates perfect
nestedness -- this network has therefore a rather high nestedness, and it makes
sense to ask whether this value is larger than expected by chance. Our
definition of \emph{chance} here will be represented by two null models: either
the nestedness is larger than expected given the value of connectance, or the
nestedness is larger than expected given the degree distribution of the network.

\subsection{Generating the null sample}

<<results="hidden">>=
P = null2(B)
R = rand(P, 5000)
@

TK

<<results="hidden">>=
f = nodf.(R)
@

We can start looking at the average value of the nestedness of the random networks:

<<>>=
mean(f)
@

Well, that didn't work.

\subsection{Fixing the null sample}

This is probably because the NODF measure is failing on some networks, and
returning a value of \texttt{NaN}. Let's see which networks are to blame:

<<results="hidden">>=
X = R[findall(isnan.(f))]
@

We can look for all sorts of reasons to understand why the NODF measure is
failing. The answer is as follows: as you will recall from section
\ref{sec:XXXX}, NODF involves dividing the number of overlapping interactions by
the XXX number of interactions. So if one species has no interactions, we would
end up dividing by 0, which would result in \texttt{NaN}. How could a species
have no interaction? The null model we use is in fact a probabilistic network,
and we know from \textcite{probanet} that there is a chance (which can be very
small), that a species will end up having no interactions if we perform
independent random draws.

This provides an interesting hypothesis: that the networks for which we do not
have a NODF score have "degenerate" matrices, after the \textcite{twosides}
nomenclature.

<<>>=
all(isdegenerate.(X))
@

This can be solved in two ways. We can either decide to remove these networks,
or we can decide to remove the species that are not connected. In section
\ref{sec:degenerate}, we will discuss the consequences of this choice, but for
now, we will remove thes networks:

<<results="hidden">>=
filter!(!isdegenerate, R)
@

We can now update the distribution of values:

<<results="hidden">>=
f = nodf.(R)
@

Visualized in \ref{fig:nhst-example1}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
    \begin{axis}[
      ybar interval,
      ymin = 0,
      xmin = 0, xmax = 1,
      xtick=,% reset from ybar interval
    ]
    \addplot+[hist={data=y, density}] table[row sep=\\,y index=0] {
    data\\
    ! print(reduce(*, string.(f).*"\\\\"))
    };
    \end{axis}
    \end{tikzpicture}
    \caption{Distribution of the values of nestedness on the simulated networks based on TK}
    \label{fig:nhst-example1}
\end{figure}


\subsection{Measuring significance}

<<>>=
sum(f .>= f0)/length(f)
@

\section{Application -- looking for generalities}

\section{Overview of the issues}

\subsection{Degenerate matrices}

\subsection{Strongly constrained matrices}

\subsection{Representativity of the sample}
